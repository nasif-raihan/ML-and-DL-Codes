{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+BXRLjY+kRp49rd+oDef6"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHzkDUQvx3mG",
        "outputId": "ff5af616-1e01-4702-f112-c2b148340d6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"\"\"On Thursday, Georgia was the staging ground for the largest\n",
        "single site immigration raid in the history of Immigration and Customs\n",
        "Enforcement’s Homeland Security Investigations wing. In total, the operation at\n",
        "the Hyundai Metaplant campus near Savannah netted 475 arrests of immigrants\n",
        "working in the U.S. without authorization, the majority of whom were Korean\n",
        "nationals, authorities said.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "WURkNzccyBMU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "fFf5b0R8HBO_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentences)):\n",
        "  words = nltk.word_tokenize(sentences[i])\n",
        "  stemmed_words = []\n",
        "  for word in words:\n",
        "    if word not in set(stopwords.words('english')):\n",
        "      print(f\"{word} -----> {stemmer.stem(word)}\")\n",
        "      stemmed_words.append(stemmer.stem(word))\n",
        "\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_js5CIM2RnE",
        "outputId": "1a96e88c-f5a4-4d4b-f5d7-5aa97c3fc00c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On -----> on\n",
            "Thursday -----> thursday\n",
            ", -----> ,\n",
            "Georgia -----> georgia\n",
            "staging -----> stage\n",
            "ground -----> ground\n",
            "largest -----> largest\n",
            "single -----> singl\n",
            "site -----> site\n",
            "immigration -----> immigr\n",
            "raid -----> raid\n",
            "history -----> histori\n",
            "Immigration -----> immigr\n",
            "Customs -----> custom\n",
            "Enforcement -----> enforc\n",
            "’ -----> ’\n",
            "Homeland -----> homeland\n",
            "Security -----> secur\n",
            "Investigations -----> investig\n",
            "wing -----> wing\n",
            ". -----> .\n",
            "In -----> in\n",
            "total -----> total\n",
            ", -----> ,\n",
            "operation -----> oper\n",
            "Hyundai -----> hyundai\n",
            "Metaplant -----> metapl\n",
            "campus -----> campu\n",
            "near -----> near\n",
            "Savannah -----> savannah\n",
            "netted -----> net\n",
            "475 -----> 475\n",
            "arrests -----> arrest\n",
            "immigrants -----> immigr\n",
            "working -----> work\n",
            "U.S. -----> u.s.\n",
            "without -----> without\n",
            "authorization -----> author\n",
            ", -----> ,\n",
            "majority -----> major\n",
            "Korean -----> korean\n",
            "nationals -----> nation\n",
            ", -----> ,\n",
            "authorities -----> author\n",
            "said -----> said\n",
            ". -----> .\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['in',\n",
              " 'total',\n",
              " ',',\n",
              " 'oper',\n",
              " 'hyundai',\n",
              " 'metapl',\n",
              " 'campu',\n",
              " 'near',\n",
              " 'savannah',\n",
              " 'net',\n",
              " '475',\n",
              " 'arrest',\n",
              " 'immigr',\n",
              " 'work',\n",
              " 'u.s.',\n",
              " 'without',\n",
              " 'author',\n",
              " ',',\n",
              " 'major',\n",
              " 'korean',\n",
              " 'nation',\n",
              " ',',\n",
              " 'author',\n",
              " 'said',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}